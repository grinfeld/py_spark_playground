FROM apache/spark:3.5.6-java17

USER root

RUN apt-get update && apt-get install -y \
    wget \
    curl

RUN apt-get update && apt-get install -y \
    python3.11 python3.11-venv python3.11-dev python3-pip

RUN cd /usr/lib/ && ln -s -f python3.11 /usr/bin/python3 && ln -s -f python3.11 /usr/bin/python

RUN rm -rf /var/lib/apt/lists/*

USER root

# Set working directory
# Note: The application code is copied in for spark-app; master/worker override CMD
# WORKDIR /app

# Spark - maybe we don't need airflow requirements
# Copy requirements first for better caching
# COPY requirements.txt .
# Install Python dependencies
# RUN pip install --no-cache-dir -r requirements.txt

USER spark

# Create directories for Spark logs and temp files
RUN mkdir -p /tmp/spark-events && mkdir -p /tmp/spark-logs

COPY spark-defaults.conf "/opt/spark/conf/spark-defaults.conf"

# Expose port for Spark UI (optional)
EXPOSE 4040
